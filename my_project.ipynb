{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495edc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"--------------------------------------------------------------------------\n",
    "This script analyzes and classifies environmental indicators (noise pollution, access to green space, surface tempertature) \n",
    "and indicators of social status to assess environmental justice at city level. Spatial level of analysis are districts.\n",
    "The code create maps, plots to visualize the results of the analysis. It\n",
    "saves a csv file with detailed statistics and results of the analyis\n",
    "------------------------------------------------------------------------------\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2952f082",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba90cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import geopandas as gpd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from cartopy.feature import ShapelyFeature\n",
    "import matplotlib.lines as mlines\n",
    "#from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "#import matplotlib.patches as mpatches\n",
    "import cartopy.crs as ccrs\n",
    "import pandas as pd\n",
    "#from shapely.geometry import Point, LineString, Polygon\n",
    "from scipy.stats import zscore\n",
    "import contextily as cx\n",
    "import rasterio as rio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340e4348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes plot interactive\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d046e9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads all of the required data to calculate the social indicator\n",
    "admin = gpd.read_file(\"data/Stadtteile_Hamburg.shp\") # boundary dataset \n",
    "stats = pd.read_csv(\"data/statistics_HH21.csv\",encoding=\"utf-8\", delimiter=\";\",decimal=\".\" ) # social statistics\n",
    "\n",
    "# loads all of the required data to calculate the environmental indicators\n",
    "noise = gpd.read_file(\"data/Laermkarten_HH_2018-11-19.shp\")#noise data set\n",
    "buildings = gpd.read_file('data/residential_buildings_HH.shp') #building dataset\n",
    "green_areas = gpd.read_file(\"data/Oeffentliche_Gruenanlage_Hamburg.shp\")#green areas dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2397eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"------- Function to reproject the datasets----------------\"\"\"\n",
    "def reproject_to_local_epsg(gdf):\n",
    "    \"\"\" Reprojects the dataframe to epsg=25832 for Hamburg. EPSG 25832 can be changed by users\n",
    "    Input: dataframe\n",
    "    \n",
    "    Returns:\n",
    "    A dataframe, reprojected to the target crs\n",
    "    Prints out the crs of the original and the resulting crs of the reprojection\n",
    "\n",
    "    \"\"\"\n",
    "    print('Original CRS:', gdf.crs)\n",
    "\n",
    "    gdf_reproj = gdf.to_crs(epsg=25832)    # Reprojects the GeoDataFrame to EPSG 25832\n",
    "    print('Reprojected CRS:', gdf_reproj.crs)\n",
    "\n",
    "    return gdf_reproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c251b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"------------------------- Functions to classify the indicators-----------------------\"\"\"\n",
    "\n",
    "def percentile_5(gpd, col_name, percentiles): # used for all environmental indicators / indicators taking 1 column as input\n",
    "    \"\"\"Classifies the dataframe into 5 equal percentiles \n",
    "\n",
    "    Parameters: \n",
    "        gpd : geodataframe, \n",
    "        col_name: column of indicator used for classification\n",
    "        percentiles : number of quantiles used for classification \"5\" : could be changed by the user but MUST be the same length as the labels\n",
    "        labels: values resulting from the classification from 0-4 (e.g. 0= lowest 20th quantile of mean / to  - 4 within highest 20th quantile)\n",
    "        \n",
    "    Returns: \n",
    "    A classified geodataframe that saves the results of the classification in a new column with the name extension _percentile. \n",
    "    The new column contains the values from 0-4\n",
    "    \n",
    "    Apply the function: \n",
    "    Example: percentile_5(dataframe, 'columNname',5)\"\"\"   \n",
    "    \n",
    "    gpd[col_name + '_percentile']  = pd.qcut(gpd[col_name], percentiles, labels=[0, 1, 2, 3, 4]) \n",
    "\n",
    "    return gpd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e5b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"-----Function to classify the dataframe for use of multiple columns--- \"\"\"\n",
    "\n",
    "def percentile_multi(gdf, col_names, percentiles): # used for social inidator in this code\n",
    "    \"\"\"Classifies the dataframe into 5 equal percentiles. Takes as input multiple columns and the sum of these\n",
    "    \n",
    "    Parameters:\n",
    "        gdf: geodataframes to classify\n",
    "        col_names: colums used for classification\n",
    "        percentiles: number of percentiles used for classification\n",
    "        labels: values resulting from classification 0-4 (same as for \"function percentile_5\")\n",
    "    \n",
    "    Returns:\n",
    "        A classified dataframe which saves the results of the classification into a new column called \"qt_soc_stats\"\n",
    "        The new column contains the values from 0-4 and constitues the sum of colums used for calculation\n",
    "        \n",
    "    Apply the function:\n",
    "        Example: percentile_multi(dataframe, ['col1', 'col1'], 5)\n",
    "    \"\"\"\n",
    "    sum_col = gdf[col_names].sum(axis=1)\n",
    "    gdf['qt_soc_stats'] = pd.qcut(sum_col, percentiles, labels=[0, 1, 2, 3, 4])\n",
    "    return gdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d578bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_status_column(df, perc_col):#The function will be used for all of the different indicators)\n",
    "    \"\"\"The function adds a text column to the dataframe based on the classification result\n",
    "\n",
    "    Parameters: \n",
    "        df : dataframe used for the classification: needs to be the same already used in the percentile_5 function \n",
    "        \n",
    "    Returns:\n",
    "        A dataframe with a new column called \"status\" containing strings with the values from \"very low\" to \"very high\"\n",
    "        Assignes the names based on the values in the perc_col\n",
    "        \n",
    "    Apply the functin:\n",
    "        Example: add_status_column(dataframe, 'columnName') # has to take the classified column:result of func percentile as input\n",
    "\n",
    "    \"\"\"\n",
    "    df['status'] = ['very low' if x == 0 else  #creates the new column \"status and then adds text description to the corresponding value\"\n",
    "                   'low' if x == 1 else\n",
    "                   'medium' if x == 2 else\n",
    "                   'high' if x == 3 else\n",
    "                   'very high' for x in df[perc_col]]\n",
    "\n",
    "    return df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f6bb4d",
   "metadata": {},
   "source": [
    "## Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a3cb22",
   "metadata": {},
   "source": [
    "#### 1)  Social Indicator\n",
    "clean and filter the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59743ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the columns to english\n",
    "stats.columns = ['district','inhabitants', 'pop<18','%<18', 'pop>65y','%>65', 'foreignResidents', 'migration_backg', 'hh','pp_size','hh_kids', '%hh_kids','areakm2', 'pop_density','working_pop', '%working_pop', 'unemployed','%unemployed','unemployed<18','%unemployed<18', 'unemployed>65', '%unemployed>65','social_benefits', '%social_benefits','social_housing', '%social_housing']\n",
    "#stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9339e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join the statistics  with the shapefile of administrative boundaries \n",
    "admin_pop = pd.merge(admin,stats, left_on='stadtteil_', right_on='district', how = 'inner')\n",
    "# drop unecessary columns in the admin dataset\n",
    "admin_pop.drop(columns=['OBJECTID','bezirk', 'stadttei_1', 'stadttei_2','pp_size', '%<18', 'hh','foreignResidents', 'migration_backg','pop<18','hh_kids', '%hh_kids', 'pop>65y', 'unemployed<18','unemployed>65','working_pop', 'social_benefits','social_housing' ],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f012b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the dataframe so that only columns relevant to the further analysis (social status) are maintained\n",
    "# null values are droppped to enable calculation\n",
    "social_stats = admin_pop[['%unemployed','%social_benefits','%social_housing','%unemployed>65' ]].dropna()\n",
    "#code then checks standard deviation \n",
    "social_stats.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75512c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses Scipy Library to calculate the z-score to normalize values  \n",
    "z_scores_admin_pop = social_stats[['%unemployed','%social_benefits','%social_housing','%unemployed>65']].apply(zscore)\n",
    "print(z_scores_admin_pop.std()) # show the std after calculation of z-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8063e586",
   "metadata": {},
   "source": [
    "#### Classification of social statistics layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1c3e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to classify the data using multiple columns on the results of the z_score calculation\n",
    "percentile_multi(z_scores_admin_pop, ['%unemployed', '%social_benefits', '%social_housing', '%unemployed>65'], 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f10abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply \"add_status_column\" function to add the status in text format\n",
    "add_status_column(z_scores_admin_pop, 'qt_soc_stats') \n",
    "#z_scores_admin_pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48175f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the newly calculated columns to differentiate from columns of original dataset\n",
    "z_scores_admin_pop.columns = ['%unemployed_z','%social_benefits_z', '%social_housing_z','%unemployed>65_z','qt_soc_stats', 'status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a84e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the social statistics to the admin dataframe to be able to plot  data later \n",
    "admin_socstats = pd.merge(admin_pop, z_scores_admin_pop, left_index=True, right_index=True) \n",
    "#drop the column with the \"old statistics\"\n",
    "admin_socstats.drop(columns=['%unemployed','%social_benefits','%social_housing','%unemployed>65']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e33eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if merged worked\n",
    "admin_socstats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f41edc",
   "metadata": {},
   "source": [
    "# 2) Environmental Indicators\n",
    "Uses noise, green areas, surface temperature? as environmental indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd4246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply \"reproject_to_local_epsg\" function to all the data  to convert CRS\n",
    "admin_pop_reproj = reproject_to_local_epsg(admin_pop)\n",
    "noise_reproj = reproject_to_local_epsg(noise)\n",
    "housing_reproj = reproject_to_local_epsg(buildings)\n",
    "green_areas_reproj = reproject_to_local_epsg(green_areas)\n",
    "boundaries_reproj = reproject_to_local_epsg(admin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bf0cf7",
   "metadata": {},
   "source": [
    "## a)  Green areas - access to and distribution\n",
    "Analyses distribution of green areas per district and area / inhabitant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9dce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete  values with code 10 = playground according to ALKIS key(official cadastre information system)\n",
    "green_areas_reproj = green_areas_reproj[green_areas_reproj.nutzung != 10] # nutzung = usage\n",
    "#drop unimportant columns from the dataset\n",
    "green_areas_reproj.drop(columns=['dgpkey', 'veroeffent','gemarkung', 'ortsteil', 'nutzung', 'nutz_code' ,'herrichtun', 'verwaltung','flaeche_qm', 'gesamtanla','aktualitae','idnr','belegenh_1','belegenhei','quelle_dat', 'stand'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a0d018",
   "metadata": {},
   "source": [
    "#### Calculation of statistics of green areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cee766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of the area  statistics for green areas per district (district = stadtteil)\n",
    "green_area_sum = green_areas_reproj.groupby(['stadtteil'])['flaeche_ha'].sum().reset_index() # group the dataset\n",
    "green_area_sum.rename(columns={'flaeche_ha': 'green_area_total_ha'}, inplace=True) # translate column name to english\n",
    "\n",
    "# Calculate mean green space area per district\n",
    "green_area_mean = green_areas_reproj.groupby(['stadtteil'])['flaeche_ha'].mean().reset_index() \n",
    "green_area_mean.rename(columns={'flaeche_ha': 'green_area_mean_ha'}, inplace=True)\n",
    "\n",
    "# Calculate the count of green spaces per district=  \"bennenung\" = unique name of green area\n",
    "green_space_count = green_areas_reproj.groupby(['stadtteil'])['benennung'].count().reset_index()\n",
    "green_space_count.rename(columns={'benennung': 'green_space_count'}, inplace=True)\n",
    "\n",
    "# Combine the statistics into one dataframe using the stadtteil column\n",
    "green_stats = pd.merge(green_area_sum, green_area_mean, on='stadtteil')\n",
    "green_stats = pd.merge(green_stats, green_space_count, on='stadtteil')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4b2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of green space from total area of the district. \"flaeche_ha\" = area of individual polygons\n",
    "green_stats['perc_green_area'] = green_areas_reproj['flaeche_ha'] / green_areas_reproj['geometry'].area * 100\n",
    "green_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f87e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the area per inhabitant  using the column \"inhabitants\" from the admin_pop_reproj dataframe\n",
    "green_stats = green_stats.merge(admin_pop_reproj[['stadtteil_', 'inhabitants']], left_on='stadtteil', right_on='stadtteil_', how='left')\n",
    "#green_stats.drop('district', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate area / inhabitant and save the results in a new column\n",
    "green_stats['area_per_inhbt'] = green_stats['inhabitants'] / green_stats['green_area_total_ha']\n",
    "green_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee1441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check std of relevant values\n",
    "green_stats[['area_per_inhbt','perc_green_area' ]].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e2441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop null values \n",
    "green_stats = green_stats.dropna(subset=['area_per_inhbt'])\n",
    "#compute  z-score for the variables used for calculation from the  greenstats data set \n",
    "z_scores_green_stats = green_stats[['area_per_inhbt','perc_green_area' ]].apply(zscore)\n",
    "\n",
    "#rename columns to distinguish from columns in original dataset\n",
    "z_scores_green_stats = z_scores_green_stats.rename(columns={'area_per_inhbt': 'z_area_per_inhbt', 'perc_green_area': 'z_perc_green_area'})\n",
    "#check the std after z-score has been applied\n",
    "z_scores_green_stats[['z_area_per_inhbt','z_perc_green_area' ]].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1789b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the original dataframe with the z-score dataframe\n",
    "green_stats_zscore = pd.concat([green_stats, z_scores_green_stats], axis=1)\n",
    "# drop  original column names: perc_green_area and _area_per_inhb\n",
    "green_stats_zscore = green_stats_zscore.drop(['area_per_inhbt', 'perc_green_area'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5cde19",
   "metadata": {},
   "source": [
    "#### Classification of green area layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29300679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply \"percentile_5\" function to classify the green_stats data into equal percentiles based on 'area_per_inhbt' column\n",
    "percentile_5(green_stats_zscore, 'z_area_per_inhbt',5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply \"add_status_column\" function using the classified \"_percentile column\"\n",
    "add_status_column(green_stats_zscore, 'z_area_per_inhbt_percentile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577694b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge statistics with a subset of the reprojected admin dataframe to enable ploting\n",
    "admin_subset = admin_pop_reproj[['district', 'geometry']]\n",
    "\n",
    "admin_greenstats = pd.merge(admin_subset, green_stats_zscore, left_index=True, right_index=True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa63ca2",
   "metadata": {},
   "source": [
    "## b) Noise Pollution \n",
    "For the noise indicator the assessment aims to identify the area of houses affected by noise and noiseclass /  district  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9ccc51",
   "metadata": {},
   "source": [
    "Analysis, filter and cleaning of the housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c41b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check data type of column \"gebaeudefu\" which indicates usage of buildings \n",
    "housing_reproj['gebaeudefu'] = housing_reproj['gebaeudefu'].astype(int)# convert the column to integer to enable calculations\n",
    "\n",
    "#drop uninmportant columns in the dataset\n",
    "housing_reproj.drop(columns=['anzahlDerU', 'lageZurErd', 'dachart', 'SHAPE_Leng'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2356ac1",
   "metadata": {},
   "source": [
    "Joins the Housing Data set to the Noise Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2fd44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use geopandas overlay method and interesect operation to determine where the noise layer intersects with the house layer \n",
    "houses_noise = gpd.overlay(housing_reproj, noise_reproj, how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3908255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#translate column names to English\n",
    "houses_noise = houses_noise.rename(columns={'name': 'noiseclass', 'anzahlDerO': 'floors', 'grundflaec':'house_area'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba55e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the dataframe to the admin dataset to plot \n",
    "admin_noisestats = gpd.sjoin(admin_pop_reproj, houses_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a90922",
   "metadata": {},
   "source": [
    "#### Calculation of Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d143ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group the dataset to get the number of houses per noiseclass and district\n",
    "houses_noiseclass = admin_noisestats.groupby(['district', 'noiseclass'])['OBJECTID'].count().reset_index()\n",
    "houses_noiseclass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa93591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mulitply the number of houses with the house area \n",
    "admin_noisestats['total_area'] = admin_noisestats['OBJECTID'] * admin_noisestats['house_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41366ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply the house area with the number of floors to get the total affected residential housing area by noiseclass\n",
    "#convert it to sqkm\n",
    "admin_noisestats['area_floors']=admin_noisestats['total_area']*admin_noisestats['floors'].astype(int)/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783caae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the noiseclass to an integer\n",
    "admin_noisestats['noiseclass'] = admin_noisestats['noiseclass'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98cf8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight the area by noiseclass in view of severity from low to high (increase by 0.5)\n",
    "weights = {0: 0.5, 1: 1, 2: 1.5, 3: 2, 4: 2.5} # dictionary to define the weights\n",
    "#use the pandas.map function to assign the weights and saves results in new column\n",
    "admin_noisestats['weighted_area'] = admin_noisestats['area_floors'] * admin_noisestats['noiseclass'].map(weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c7878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group data by district and weighted area\n",
    "noisestats_weighted = admin_noisestats.groupby('district')['weighted_area'].sum().reset_index()\n",
    "#admin_noisestats.head() # recommended to not display the output due to its size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ef106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply function thats classifies dataframe into percentiles based on the weighted_area column\n",
    "percentile_5(noisestats_weighted, 'weighted_area',5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the \"add_status_column\" function\n",
    "add_status_column(noisestats_weighted, 'weighted_area_percentile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b5fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the noise statistics  with a subset of the reprojected admin data to plot later\n",
    "\n",
    "noisestats_merged = pd.merge(admin_subset, noisestats_weighted, left_index=True, right_index=True)\n",
    "noisestats_merged.rename(columns={'district_x': 'district'}, inplace=True)\n",
    "noisestats_merged.drop('district_y', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e1a450",
   "metadata": {},
   "source": [
    "## Visualizations of Indicators\n",
    "Create maps and plots for the different indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e273a89d",
   "metadata": {},
   "source": [
    "Save the dataframes with the calculations in csv format to output folder in GITHUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd9783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the final data frames as csv file into the ouptut folder on Github                                                                   \n",
    "#admin_socstats.to_csv(\"./output/social_stats.csv\")\n",
    "#noisestats_merged.to_csv(\"./output/noise_stats.csv\")\n",
    "#admin_greenstats.to_csv(\"./output/green_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c205175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to define parameters for mapping of indicators\n",
    "def plot_stats(gdf, title, color): # defines the parameterrs that need to be adapted for the individual plots\n",
    "    \n",
    "    #  defines order of the status lassification\n",
    "    status_order = ['very low', 'low', 'medium', 'high', 'very high']\n",
    "\n",
    "    # convert the status column to a categorical variable with the defined order\n",
    "    gdf['status'] = pd.Categorical(gdf['status'], categories=status_order, ordered=True) # from low to high\n",
    "\n",
    "    # sorts the gvalues\n",
    "    gdf = gdf.sort_values('status')\n",
    "    \n",
    "    # Creates a figure and defines the size of it\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    # Plots the data using the the status column\n",
    "    gdf.plot(\"status\", cmap=color, legend=True, ax=ax) # shows the legend\n",
    "    \n",
    "    legend = ax.get_legend()\n",
    "    legend.set_title(\"Status\") # adds the legend title\n",
    "\n",
    "    # Sets the title and style of the plot\n",
    "    ax.set_title(title,fontweight=\"bold\")\n",
    "    \n",
    "    cx.add_basemap(ax,source=cx.providers.Stamen.TonerLite)\n",
    "\n",
    "    #adds the district name to the plot and defines some style parameters\n",
    "    gdf.apply(lambda x: ax.annotate(text=x['district'], xy=x.geometry.centroid.coords[0], ha='center', color=\"grey\", size=7), axis=1)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    # Displays the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3885ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply plotting function to the indicator \n",
    "plot_stats(admin_socstats,\"Indicator Social Status - Classified by percentile \", \"Oranges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0cbaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stats(admin_greenstats, \"Indicator Access to Green Areas - Classified by percentile\", \"YlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d715e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stats(noisestats_merged, \"Indicator Noise Pollution - Classified by percentile \", \"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ec12a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset the social stats dataset to keep only relevant columns for merge\n",
    "soc_subset = admin_socstats[[\"bezirk_nam\",\"district\",\"geometry\", \"status\",\"qt_soc_stats\", \"%unemployed\",\"%social_benefits\",\"%social_housing\"]]\n",
    "#rename status columns in all dataframes to avoid duplications\n",
    "soc_subset=soc_subset.rename(columns={\"status\":\"status_soc\"})\n",
    "green_subset=green_stats_zscore.rename(columns={\"status\":\"status_greens\"})\n",
    "noisestats_merged=noisestats_merged.rename(columns={\"status\":\"status_noise\"})\n",
    "noisestats_merged.drop(columns=['geometry']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad205f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the statistics data set to have one single dataframe for relevant statistics\n",
    "stats_merged = green_subset.merge(soc_subset, left_on='stadtteil', right_on='district', how='inner')\n",
    "stats_merged = stats_merged.merge(noisestats_merged, left_on='district', right_on='district', how='right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec373f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "#stats_merged.to_csv(\"./output/stats_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bbf155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only select the classified status indicators into 1 data set. \n",
    "stat_indicators=stats_merged[['district','weighted_area_percentile','qt_soc_stats','z_area_per_inhbt','status_soc','status_greens','status_noise']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57166786",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_indicators.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b56782",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d47a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70dbe16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
