{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2952f082",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba90cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.patches as mpatches\n",
    "import cartopy.crs as ccrs\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from scipy.stats import zscore\n",
    "import rasterio as rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340e4348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes plot interactive\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a3cb22",
   "metadata": {},
   "source": [
    "# 1)  Social Indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85476d89",
   "metadata": {},
   "source": [
    "Loads & clean data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3688b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the  data to calculate the social indicator from local machine\n",
    "admin = gpd.read_file(\"C:/Users/charl/OneDrive/Desktop/ulster/EGM722_programming/git/egm722_project/data/Stadtteile_Hamburg.shp\")\n",
    "stats = pd.read_csv(\"C:/Users/charl/OneDrive/Desktop/ulster/EGM722_programming/git/egm722_project/data/statistics_HH21.csv\",encoding=\"utf-8\", delimiter=\";\",decimal=\".\" )\n",
    "#admin.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59743ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renames the columns to english\n",
    "stats.columns = ['district','inhabitants', 'pop<18','%<18', 'pop>65y','%>65', 'foreignResidents', 'migration_backg', 'hh','pp_size','hh_kids', '%hh_kids','areakm2', 'pop_density','working_pop', '%working_pop', 'unemployed','%unemployed','unemployed<18','%unemployed<18', 'unemployed>65', '%unemployed>65','social_benefits', '%social_benefits','social_housing', '%social_housing']\n",
    "#stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9339e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joins the population data with the shapefile of administrative boundaries and dropped unecessary columns in the admin dataset\n",
    "admin_pop = pd.merge(admin,stats, left_on='stadtteil_', right_on='district', how = 'inner')\n",
    "\n",
    "admin_pop.drop(columns=['OBJECTID','bezirk', 'stadttei_1', 'stadttei_2','pp_size', '%<18', 'hh','foreignResidents', 'migration_backg','pop<18','hh_kids', '%hh_kids', 'pop>65y', 'unemployed<18', ],axis=1, inplace=True)\n",
    "\n",
    "#admin_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f012b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line of code first subsets the dataframe so that only numeric columns relevant to the further anylsis (social status) are maintained\n",
    "# null values are droppped to enable calculation\n",
    "social_stats = admin_pop[['%unemployed','%social_benefits','%social_housing','%unemployed>65' ]].dropna()\n",
    "#code then checks standard deviation \n",
    "social_stats.hist()\n",
    "social_stats.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75512c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scipy Library in Python is used to calculate the z-score which helps to standardize the values for each column \n",
    "\n",
    "z_scores_admin_pop = social_stats[['%unemployed','%social_benefits','%social_housing','%unemployed>65']].apply(zscore)\n",
    "\n",
    "print(z_scores_admin_pop.std()) # shows the std after calculation of z-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8063e586",
   "metadata": {},
   "source": [
    "#### Classification of social statistics layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb3fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#groups & classifies the results into equal percentiles \n",
    "# Quantiles from 0-4 (e.g. 0= lowest 20th quantile of mean  to 4 = within highest 20th quantile))\n",
    "#and saves the results to a new column. All the 4 indicators are equally weighted. \n",
    "z_scores_admin_pop['qt_soc_stats'] = pd.qcut(z_scores_admin_pop['%unemployed'] + z_scores_admin_pop['%social_benefits'] + z_scores_admin_pop['%social_housing'] + z_scores_admin_pop['%unemployed>65'], 5, labels=[0, 1, 2, 3, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f10abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function adds a text column to the dataframe based on the classification into percentiles\n",
    "#The function will be used for all of the different indicators)\n",
    "def add_status_column(df, zscore_mean_column):\n",
    "    df['status'] = ['very low' if x == 0 else  #creates the new column \"status and then adds text description to the corresponding value\"\n",
    "                   'low' if x == 1 else\n",
    "                   'medium' if x == 2 else\n",
    "                   'high' if x == 3 else\n",
    "                   'very high' for x in df[zscore_mean_column]]\n",
    "\n",
    "# Applies the function to the data set based on the values in the stats column\n",
    "add_status_column(z_scores_admin_pop, 'qt_soc_stats') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88096940",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores_admin_pop.head() # checks if the operation has worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a84e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merges the social statistics  to the admin data frame to be able to plot the data later \n",
    "admin_socstats = pd.merge(admin_pop, z_scores_admin_pop, left_index=True, right_index=True) #Uses the index to perform the merge operation\n",
    "admin_socstats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f41edc",
   "metadata": {},
   "source": [
    "# 2) Environmental Indicators\n",
    "Uses noise, green areas, surface temperature? as environmental indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58faff-b462-4da8-9f4b-a08dee3c85f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads the data for analysis of environmental indicators\n",
    "noise = gpd.read_file(\"C:/Users/charl/OneDrive/Desktop/ulster/EGM722_programming/git/egm722_project/data/Laermkarten_HH_2018-11-19.shp\")\n",
    "buildings = gpd.read_file(\"C:/Users/charl/OneDrive/Desktop/ulster/EGM722_programming/git/egm722_project/data/Gebaeude_Hamburg.shp\")\n",
    "green_areas = gpd.read_file(\"C:/Users/charl/OneDrive/Desktop/ulster/EGM722_programming/git/egm722_project/data/Oeffentliche_Gruenanlage_Hamburg.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd4246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function checks the crs of different layers and reprojects them to the target EPSG for Hamburg, GE(25832) for spatial operations\n",
    "def reproject_to_local_epsg(gdf):\n",
    "    # Checks the CRS of the input GeoDataFrame\n",
    "    print('Original CRS:', gdf.crs)\n",
    "\n",
    "    # Reprojects the GeoDataFrame to EPSG 25832\n",
    "    gdf_reproj = gdf.to_crs(epsg=25832)\n",
    "\n",
    "    # Prints out the CRS of the output GeoDataFrame\n",
    "    print('Reprojected CRS:', gdf_reproj.crs)\n",
    "\n",
    "    return gdf_reproj\n",
    "\n",
    "# applies function to all the data  to convert CRS\n",
    "admin_pop_reproj = reproject_to_local_epsg(admin_pop)\n",
    "noise_reproj = reproject_to_local_epsg(noise)\n",
    "housing_reproj = reproject_to_local_epsg(buildings)\n",
    "green_areas_reproj = reproject_to_local_epsg(green_areas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bf0cf7",
   "metadata": {},
   "source": [
    "## a)  Green areas - access to and distribution\n",
    "Analyses distribution of green areas per district and area / inhabitant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16df94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#green_areas_reproj.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9dce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deletes the values with code 10 = playground according to ALKIS key(official cadastre information system\n",
    "green_areas_reproj = green_areas_reproj[green_areas_reproj.nutzung != 10]\n",
    "\n",
    "#drops unimportant columns from the dataset\n",
    "green_areas_reproj.drop(columns=['veroeffent', 'nutzung', 'nutz_code' ,'herrichtun', 'gesamtanla','aktualitae','idnr','belegenh_1','belegenhei','quelle_dat', 'stand'],axis=1, inplace=True)\n",
    "\n",
    "green_areas_reproj.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a0d018",
   "metadata": {},
   "source": [
    "#### Calculation of statistics of green areas at district level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cee766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the sum of the area  statistics for the green areas per district (district = stadtteil)\n",
    "green_area_sum = green_areas_reproj.groupby(['stadtteil'])['flaeche_ha'].sum().reset_index() # groups the dataset\n",
    "green_area_sum.rename(columns={'flaeche_ha': 'green_area_total_ha'}, inplace=True) # renames the columns\n",
    "\n",
    "# Calculates mean green space area per district\n",
    "green_area_mean = green_areas_reproj.groupby(['stadtteil'])['flaeche_ha'].mean().reset_index() \n",
    "green_area_mean.rename(columns={'flaeche_ha': 'green_area_mean_ha'}, inplace=True)\n",
    "\n",
    "# Calculates the count of green spaces per district=  \"Bennenung\" = unique name of green area\n",
    "green_space_count = green_areas_reproj.groupby(['stadtteil'])['benennung'].count().reset_index()\n",
    "green_space_count.rename(columns={'benennung': 'green_space_count'}, inplace=True)\n",
    "\n",
    "# Combines the statistics into one data frame using the stadtteil column\n",
    "green_stats = pd.merge(green_area_sum, green_area_mean, on='stadtteil')\n",
    "green_stats = pd.merge(green_stats, green_space_count, on='stadtteil')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4b2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the percentage of green space from total area of the district\n",
    "green_stats['perc_green_area'] = green_areas_reproj['flaeche_ha'] / green_areas_reproj['geometry'].area * 100\n",
    "green_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f87e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally calculates the area per inhabitant by using the column inhabitants from the admin_pop_reproj dataframe\n",
    "# adds the column to the green_stats data frame\n",
    "green_stats = green_stats.merge(admin_pop_reproj[['stadtteil_', 'inhabitants']], left_on='stadtteil', right_on='stadtteil_', how='left')\n",
    "green_stats.drop('stadtteil_', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates thearea / inhabitant and saves the results in a new column\n",
    "green_stats['area_per_inhbt'] = green_stats['inhabitants'] / green_stats['green_area_total_ha']\n",
    "green_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee1441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks std of relevant values\n",
    "green_stats[['area_per_inhbt','perc_green_area' ]].std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5cde19",
   "metadata": {},
   "source": [
    "#### Classification of green area layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f2a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function classifies the statistics into 5 equal percentiles. The function will be used for all the environmental variables \n",
    "# uses the same approach as for the social indicator: quantiles 0-4 (e.g. 0= lowest 20th quantile of mean / to  - 4 within highest 20th quantile)\n",
    "def percentile_5(gpd, col_name, percentiles): \n",
    "    #defines the name of the new column to save the results , then classifies the dataset into 5 equal percentiles 0-4\n",
    "    gpd[col_name + '_percentile']  = pd.qcut(gpd[col_name], percentiles, labels=[0, 1, 2, 3, 4]) # col_name= column used for classification\n",
    "\n",
    "    return gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29300679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applies the function to classify the green_stats data into equal percentiles based on 'area_per_inhbt' column\n",
    "percentile_5(green_stats, 'area_per_inhbt',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applies the add status column function defined earlier based on the classified \"percentile column\"\n",
    "add_status_column(green_stats, 'area_per_inhbt_percentile')\n",
    "green_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577694b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merges the green statistics computed to the reprojected admin data frame to be able to plot the data later on\n",
    "admin_greenstats = pd.merge(admin_pop_reproj, green_stats, left_index=True, right_index=True)\n",
    "admin_greenstats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa63ca2",
   "metadata": {},
   "source": [
    "## b) Noise Pollution \n",
    "For the noise indicator the assessment aims to identify the area of houses affected by noise and noiseclass /  district  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9ccc51",
   "metadata": {},
   "source": [
    "Analysis, filter and cleaning of the Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c41b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#housing_reproj.columns\n",
    "#checks data type of column gebaeudefu which indicates usage of houses \n",
    "housing_reproj['gebaeudefu'] = housing_reproj['gebaeudefu'].astype(int)# converts the column to integer to enable calculations\n",
    "\n",
    "#drops uninmportant columns in the dataset\n",
    "housing_reproj.drop(columns=['anzahlDerU', 'lageZurErd', 'dachart', 'SHAPE_Leng'],axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81c571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters out any non-residential housing from the data set and keeps only residential buildings ALKIS Keys (1000 and 1010 )\n",
    "housing_reproj = housing_reproj[(housing_reproj['gebaeudefu'] == 1010) | (housing_reproj['gebaeudefu'] == 1000)]\n",
    "#housing_reproj.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0de14a3",
   "metadata": {},
   "source": [
    "Analysis, filter and cleaning of the Noise Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d845c83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###checks out the noise data set, which is a classified shapefile:name here stands for severity of noise from 0 low to 4 highest\n",
    "noise_reproj.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2356ac1",
   "metadata": {},
   "source": [
    "Joins the Housing Data set to the Noise Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2fd44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code uses the geopandas overlay method and interesect operation to determine where the noise layer intersects with the house layer \n",
    "houses_noise = gpd.overlay(housing_reproj, noise_reproj, how='intersection')\n",
    "#houses_noise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3908255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renames column names to noiseclass and anzahDerO to English = number of floors and grundflaec to house_area\n",
    "houses_noise = houses_noise.rename(columns={'name': 'noiseclass', 'anzahlDerO': 'floors', 'grundflaec':'house_area'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba55e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joins the data frame to the admin dataset to be able to plot the data later\n",
    "admin_noisestats = gpd.sjoin(admin_pop_reproj, houses_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9bd8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#admin_noisestats.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a90922",
   "metadata": {},
   "source": [
    "#### Calculation of Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d143ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#groups the dataset to get the number of houses per noiseclass and district\n",
    "houses_noiseclass = admin_noisestats.groupby(['district', 'noiseclass'])['OBJECTID'].count().reset_index()\n",
    "houses_noiseclass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa93591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mulitplies the number of houses with the house area \n",
    "admin_noisestats['total_area'] = admin_noisestats['OBJECTID'] * admin_noisestats['house_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41366ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiplies the house area with the number of floors to get the total affected residential housing area by noiseclass\n",
    "admin_noisestats['area_floors']=admin_noisestats['total_area']*admin_noisestats['floors'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c666b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#admin_noisestats['total_area_floors'].hist()\n",
    "#admin_noisestats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783caae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts the noiseclass to an integer\n",
    "admin_noisestats['noiseclass'] = admin_noisestats['noiseclass'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98cf8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights the area by noiseclass in view of severity from low to high (increase by 0.5)\n",
    "weights = {0: 0.5, 1: 1, 2: 1.5, 3: 2, 4: 2.5} # dictionary to define the weights\n",
    "#applies the weights and saves the results in a new column\n",
    "#uses  the pandas.map function to assign the weights\n",
    "admin_noisestats['weighted_area'] = admin_noisestats['area_floors'] * admin_noisestats['noiseclass'].map(weights) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c7878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#groups data set by district and weighted area\n",
    "noisestats_weighted = admin_noisestats.groupby('district')['weighted_area'].sum().reset_index()\n",
    "#admin_noisestats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ef106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applies function thats classifies dataframe   into percentiles\n",
    "percentile_5(noisestats_weighted, 'weighted_area',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applies the add status column function defined earlier\n",
    "add_status_column(noisestats_weighted, 'weighted_area_percentile')\n",
    "noisestats_weighted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b5fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merges the grouped data set with the weighted area with the orignial merged noisedata to prepare for plotting\n",
    "noisestats_merged = pd.merge(admin_noisestats, noisestats_weighted, left_index=True, right_index=True)\n",
    "noisestats_merged.head()\n",
    "noisestats_merged = noisestats_merged.rename(columns={'district_x': 'district'}) # renames the column to use it in the plot function later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc8845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves the final data pollution statistics as csv file into the ouptut folder on Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992e88f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisestats_merged.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19271f5e",
   "metadata": {},
   "source": [
    "## Visualizations of Indicators\n",
    "Create maps and plots for the different indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cde6377",
   "metadata": {},
   "source": [
    "Saves the dataframes with the calculations in csv format to output folder in GITHB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5592ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves the final data frames as csv file into the ouptut folder on Github\n",
    "\n",
    "admin_socstats.to_csv(\"./output/social_stats.csv\")\n",
    "noisestats_merged.to_csv(\"./output/noise_stats.csv\")\n",
    "admin_greenstats.to_csv(\"./output/green_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b07aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to define parameters for plotting od indicators\n",
    "def plot_stats(gdf, title, color ): # defines the parameterrs that need to be adapted for the individual plots\n",
    "    # Create a figure and axis object with a size of 12x16 inches\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    # Plots the data using the the status column\n",
    "    gdf.plot(\"status\", cmap=color, legend=True, ax=ax) # shows the legend\n",
    "    \n",
    "    legend = ax.get_legend()\n",
    "    legend.set_title(\"Status\") # adds the legend title\n",
    "\n",
    "    # Sets the title of the plot\n",
    "    ax.set_title(title,fontweight=\"bold\")\n",
    "    \n",
    "    #adds the district name to the plot and defines some style parameters\n",
    "    gdf.apply(lambda x: ax.annotate(text=x['district'], xy=x.geometry.centroid.coords[0], ha='center', color=\"indigo\", size=6), axis=1);\n",
    " \n",
    "    # Turns off the axis labels\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    # Displays the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ff9d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "## applies the function to the individual indicators created \n",
    "plot_stats(noisestats_merged, \"Noise Pollution - Percentiles\", \"Blues\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1873d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stats(admin_socstats, \"Social Status - Percentiles\", \"Oranges\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faccdc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_stats(admin_greenstats, \"Green Areas per Inhabitant - Percentiles\", \"YlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03bd979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
