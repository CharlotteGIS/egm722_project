{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ff7359",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"--------------------------------------------------------------------------\n",
    "This script analyzes and classifies environmental indicators (noise pollution, green space supply, brigtness temperature) \n",
    "and indicators of social status to assess environmental justice at city level. Spatial level of analysis are districts.\n",
    "The code create maps and plots to visualize the results of the analysis. The results and visual outputs are saved to the \n",
    "\"output\" folder\n",
    "------------------------------------------------------------------------------\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2952f082",
   "metadata": {},
   "source": [
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba90cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import cartopy.crs as ccrs\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import contextily as cx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340e4348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes plot interactive\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634f6c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads all of the required data to calculate the social indicator\n",
    "admin = gpd.read_file(\"data/Stadtteile_Hamburg.shp\") # boundary dataset \n",
    "stats = pd.read_csv(\"data/statistics_HH21.csv\",encoding=\"utf-8\", delimiter=\";\",decimal=\".\" ) # social statistics\n",
    "\n",
    "# loads all of the required data to calculate the environmental indicators\n",
    "noise = gpd.read_file(\"data/Laermkarten_HH_2018-11-19.shp\") #noise data set\n",
    "buildings = gpd.read_file('data/residential_buildings_HH.shp') #building dataset\n",
    "green_areas = gpd.read_file(\"data/Oeffentliche_Gruenanlage_Hamburg.shp\") #green areas dataset\n",
    "brightnesstemp =pd.read_csv(\"data/temp_stats.csv\",encoding=\"utf-8\", delimiter=\";\",decimal=\",\" ) # temperature data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7968b84a",
   "metadata": {},
   "source": [
    "#### Functions used in the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f8f414",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"------- Function to reproject the datasets----------------\"\"\"\n",
    "def reproject_to_local_epsg(gdf):\n",
    "    \"\"\" Reprojects the dataframe to epsg=25832 for Hamburg. EPSG 25832\n",
    "    \n",
    "    Input: dataframe\n",
    "    \n",
    "    Returns:\n",
    "    A dataframe, reprojected to the target crs as specified in the function\n",
    "    Prints out the crs of the original and of the  crs of the reprojection\n",
    "\n",
    "    \"\"\"\n",
    "    print('Original CRS:', gdf.crs)\n",
    "\n",
    "    gdf_reproj = gdf.to_crs(epsg=25832)    # Reprojects the GeoDataFrame to EPSG 25832\n",
    "    print('Reprojected CRS:', gdf_reproj.crs)\n",
    "\n",
    "    return gdf_reproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d753e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"------------------------- Function to classify the indicators-----------------------\"\"\"\n",
    "\n",
    "def percentile_5(gpd, col_name, percentiles): # used for all environmental indicators / indicators taking 1 column as input\n",
    "    \"\"\"Classifies the dataframe into 5 equal percentiles \n",
    "\n",
    "    Parameters: \n",
    "        gpd : geodataframe \n",
    "        col_name: column of indicator used for classification\n",
    "        percentiles : number of quantiles used for classification \"5\" : MUST be the same length as the labels\n",
    "        labels: values resulting from the classification from 0-4 (e.g. 0= lowest 20th quantile of mean / to 4 within highest 20th quantile)\n",
    "        \n",
    "    Returns: \n",
    "    A classified geodataframe that saves the results of the classification in a new column with the name extension _percentile. \n",
    "    The new column contains the values from 0-4\n",
    "    \n",
    "    Apply the function: \n",
    "    Example: percentile_5(dataframe, 'columName',5)\"\"\"   \n",
    "    \n",
    "    gpd[col_name + '_percentile']  = pd.qcut(gpd[col_name], percentiles, labels=[0, 1, 2, 3, 4]) \n",
    "\n",
    "    return gpd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1c7082",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"-----Function to classify the dataframe for use of multiple columns--- \"\"\"\n",
    "\n",
    "def percentile_multi(gdf, col_names, percentiles): # used for social inidator in this code\n",
    "    \"\"\"Classifies the dataframe into 5 equal percentiles. Takes as input multiple columns and the sum of these\n",
    "    \n",
    "    Parameters:\n",
    "        gdf: geodataframes with the columns used for classification\n",
    "        col_names: colums used for classification\n",
    "        percentiles: number of percentiles used for classification\n",
    "        labels: values resulting from classification 0-4 (same as for \"function percentile_5\")\n",
    "    \n",
    "    Returns:\n",
    "        A dataframe which saves the results of the classification by percentiles into a new column called \"qt_soc_stats\"\n",
    "        The new column contains the values from 0-4 and constitutes the sum of colums used for calculation\n",
    "        \n",
    "    Apply the function:\n",
    "        Example: percentile_multi(dataframe, ['col1', 'col2'], 5)\n",
    "    \"\"\"\n",
    "    sum_col = gdf[col_names].sum(axis=1)\n",
    "    gdf['qt_soc_stats'] = pd.qcut(sum_col, percentiles, labels=[0, 1, 2, 3, 4])\n",
    "    return gdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71463407",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"-----Function to add a status column  --- \"\"\"\n",
    "\n",
    "def add_status_column(df, perc_col): #The function will be used for all of the different indicators)\n",
    "    \"\"\"The function adds a text column to the dataframe. The value of the text column is assigned based\n",
    "        on the values of the classified \"_percentile column\"\n",
    "\n",
    "    Parameters: \n",
    "        df : dataframe used for the classification\n",
    "        perc_col: Column used to assign te the text values: NEEDS to be a categorial variable, resulting from the \n",
    "        \"percentile functions\" Has to take the classified column:result of func percentile as input\n",
    "        \n",
    "    Returns:\n",
    "        A dataframe with a new column called \"status\" containing strings with the values from \"very low\" to \"very high\"\n",
    "        Assignes the names based on the values in the perc_col\n",
    "        \n",
    "    Apply the functin:\n",
    "        Example: add_status_column(dataframe, 'columnName') # \n",
    "\n",
    "    \"\"\"\n",
    "    df['status'] = ['very low' if x == 0 else  #creates the new column \"status and then adds text description to the corresponding value\"\n",
    "                   'low' if x == 1 else\n",
    "                   'medium' if x == 2 else\n",
    "                   'high' if x == 3 else\n",
    "                   'very high' for x in df[perc_col]]\n",
    "\n",
    "    return df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec68f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"-----Function to create map--------------- \"\"\"\n",
    "\n",
    "# function to define parameters for mapping of indicators\n",
    "def plot_stats(gdf, title, color,output_path):   \n",
    "    \"\"\" The function creates a map to visualize the ranking of each classified indicator\n",
    "    \n",
    "    Parameters: \n",
    "        gdf : dataframe used for the map\n",
    "        title: title to be displayed on the map\n",
    "        color: allows the user to specify the colors used for visualization\n",
    "        output_path: output_path to save the map with unique name \n",
    "        \n",
    "        IMPORTANT: gdf for plotting has to contain a categorial column called \"status\"\n",
    "        \n",
    "    Returns:\n",
    "        A cloropleth map visualizing the ranking of each district by percentile which is the result of the classification\n",
    "        The map uses the \"status\" column representing the result of the classification for each indicator\n",
    "        The percentile ranking is ordered in ascending order from very low to very high  \n",
    "        The map displays a legend, basemap and allows distinct colormaps and titles based on the input parameters\n",
    "        The map is automatically saved in png format\n",
    "        \n",
    "    Apply the functin:\n",
    "        Example: plot_stats(your gdf,\"title goes here\", \"color\")\n",
    "\n",
    "    \"\"\"    \n",
    "    status_order = ['very low', 'low', 'medium', 'high', 'very high'] # order used for plotting\n",
    "\n",
    "    # convert the status column to a categorical variable with the defined order\n",
    "    gdf['status'] = pd.Categorical(gdf['status'], categories=status_order, ordered=True) \n",
    "\n",
    "    # sort the values\n",
    "    gdf = gdf.sort_values('status')\n",
    "    \n",
    "    # Create a figure and define the size \n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "    # Plotsthe data using the status column \n",
    "    gdf.plot(\"status\", cmap=color, legend=True, ax=ax) \n",
    "    \n",
    "    legend = ax.get_legend()\n",
    "    legend.set_title(\"Percentile Ranking\") # add the legend title\n",
    "        \n",
    "    #Set the title and style \n",
    "    ax.set_title(title, fontweight=\"bold\", fontsize=14, color=\"#444444\")\n",
    "    \n",
    "    #add basemap\n",
    "    cx.add_basemap(ax,source=cx.providers.Stamen.TonerLite)\n",
    "\n",
    "    #add the district name to the map polygons and define some style parameters\n",
    "    gdf.apply(lambda x: ax.annotate(text=x['district'], xy=x.geometry.centroid.coords[0], ha='center', color=\"grey\", size=7), axis=1)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    fig.savefig(output_path, dpi=300)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a3cb22",
   "metadata": {},
   "source": [
    "# 1)  Social Indicator\n",
    "Clean and filter the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59743ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#translate columns to English\n",
    "stats.columns = ['district','inhabitants', 'pop<18','%<18', 'pop>65y','%>65', 'foreignResidents', 'migration_backg', 'hh','pp_size','hh_kids', '%hh_kids','areakm2', 'pop_density','working_pop', '%working_pop', 'unemployed','%unemployed','unemployed<18','%unemployed<18', 'unemployed>65', '%unemployed>65','social_benefits', '%social_benefits','social_housing', '%social_housing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9339e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join the csv file with the statistics with the shapefile of administrative boundaries \n",
    "admin_pop = pd.merge(admin,stats, left_on='stadtteil_', right_on='district', how = 'inner')\n",
    "# drop unecessary columns in the admin dataset\n",
    "admin_pop.drop(columns=['OBJECTID','bezirk', 'stadttei_1', 'stadttei_2','pp_size', '%<18', 'hh','foreignResidents', 'migration_backg','pop<18','hh_kids', '%hh_kids', 'pop>65y', 'unemployed<18','unemployed>65','working_pop', 'social_benefits','social_housing' ],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f012b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the dataframe so that only columns relevant to the further analysis (social status) are maintained\n",
    "# NULL values are droppped to enable calculation\n",
    "social_stats = admin_pop[['%unemployed','%social_benefits','%social_housing','%unemployed>65' ]].dropna()\n",
    "#code then checks standard deviation \n",
    "social_stats.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75512c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Scipy Library to calculate the z-score to normalize values  \n",
    "z_scores_admin_pop = social_stats[['%unemployed','%social_benefits','%social_housing','%unemployed>65']].apply(zscore)\n",
    "print(z_scores_admin_pop.std()) # show the std after calculation of z-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8063e586",
   "metadata": {},
   "source": [
    "#### Classification of social statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a032e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the \"percentile_multi\" function to classify the data using on the results of the z_score calculation\n",
    "percentile_multi(z_scores_admin_pop, ['%unemployed', '%social_benefits', '%social_housing', '%unemployed>65'], 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f10abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the \"add_status_column\" function to add the status in text format\n",
    "add_status_column(z_scores_admin_pop, 'qt_soc_stats') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48175f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the newly calculated columns to differentiate from columns of original dataset\n",
    "z_scores_admin_pop.columns = ['%unemployed_z','%social_benefits_z', '%social_housing_z','%unemployed>65_z','qt_soc_stats', 'status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a84e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the social statistics to the admin dataframe to be able to plot  data later \n",
    "admin_socstats = pd.merge(admin_pop, z_scores_admin_pop, left_index=True, right_index=True) \n",
    "#drop the column with the \"old statistics\"\n",
    "admin_socstats.drop(columns=['%unemployed','%social_benefits','%social_housing','%unemployed>65']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f41edc",
   "metadata": {},
   "source": [
    "# 2) Environmental Indicators\n",
    "As environmental indicator the script calculates: noise burden, green area supply, surface temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd4246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply \"reproject_to_local_epsg\" function to all the dataframes to convert to same target CRS\n",
    "admin_pop_reproj = reproject_to_local_epsg(admin_pop)\n",
    "noise_reproj = reproject_to_local_epsg(noise)\n",
    "housing_reproj = reproject_to_local_epsg(buildings)\n",
    "green_areas_reproj = reproject_to_local_epsg(green_areas)\n",
    "boundaries_reproj = reproject_to_local_epsg(admin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bf0cf7",
   "metadata": {},
   "source": [
    "## a)  Green areas supply and spatial distribution\n",
    "Analyzes distribution of green areas per district and area / inhabitant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9dce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete  values with code 10 = playground according to ALKIS key(official cadastre information system)\n",
    "green_areas_reproj = green_areas_reproj[green_areas_reproj.nutzung != 10] # nutzung = usage\n",
    "#drop unimportant columns from the dataset\n",
    "green_areas_reproj.drop(columns=['dgpkey', 'veroeffent','gemarkung', 'ortsteil', 'nutzung', 'nutz_code' ,'herrichtun', 'verwaltung','flaeche_qm', 'gesamtanla','aktualitae','idnr','belegenh_1','belegenhei','quelle_dat', 'stand'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a0d018",
   "metadata": {},
   "source": [
    "#### Calculation of statistics of green areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cee766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of the area  statistics for green areas per district (district = stadtteil)\n",
    "green_area_sum = green_areas_reproj.groupby(['stadtteil'])['flaeche_ha'].sum().reset_index() # group the dataset\n",
    "green_area_sum.rename(columns={'flaeche_ha': 'green_area_total_ha'}, inplace=True) # translate column name to English\n",
    "\n",
    "# Calculate mean green space area per district\n",
    "green_area_mean = green_areas_reproj.groupby(['stadtteil'])['flaeche_ha'].mean().reset_index() \n",
    "green_area_mean.rename(columns={'flaeche_ha': 'green_area_mean_ha'}, inplace=True)\n",
    "\n",
    "# Calculate the count of green spaces per district = \"bennenung\" = unique name of green area\n",
    "green_space_count = green_areas_reproj.groupby(['stadtteil'])['benennung'].count().reset_index()\n",
    "green_space_count.rename(columns={'benennung': 'green_space_count'}, inplace=True)\n",
    "\n",
    "# Combine the statistics into one dataframe using the stadtteil column\n",
    "green_stats = pd.merge(green_area_sum, green_area_mean, on='stadtteil')\n",
    "green_stats = pd.merge(green_stats, green_space_count, on='stadtteil')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4b2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of green space from total area of the district: \"flaeche_ha\" = area of individual polygons\n",
    "green_stats['perc_green_area'] = green_areas_reproj['flaeche_ha'] / green_areas_reproj['geometry'].area * 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f87e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with admin data to access information on inhabitants per district\n",
    "green_stats = green_stats.merge(admin_pop_reproj[['stadtteil_', 'inhabitants']], left_on='stadtteil', right_on='stadtteil_', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate area / inhabitant and save the results in a new column\n",
    "green_stats['area_per_inhbt'] = green_stats['inhabitants'] / green_stats['green_area_total_ha']\n",
    "green_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee1441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check std of relevant values used for classification\n",
    "green_stats[['area_per_inhbt','perc_green_area' ]].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e2441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Null values \n",
    "green_stats = green_stats.dropna(subset=['area_per_inhbt'])\n",
    "#compute  z-score for the variables used for calculation from the  green_stats data  \n",
    "z_scores_green_stats = green_stats[['area_per_inhbt','perc_green_area' ]].apply(zscore)\n",
    "\n",
    "#rename columns to distinguish from columns in original dataset\n",
    "z_scores_green_stats = z_scores_green_stats.rename(columns={'area_per_inhbt': 'z_area_per_inhbt', 'perc_green_area': 'z_perc_green_area'})\n",
    "#check the std after z-score has been applied\n",
    "z_scores_green_stats[['z_area_per_inhbt','z_perc_green_area' ]].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1789b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the original dataframe with the z-score dataframe\n",
    "green_stats_zscore = pd.concat([green_stats, z_scores_green_stats], axis=1)\n",
    "# drop  original column names: perc_green_area and _area_per_inhb\n",
    "green_stats_zscore = green_stats_zscore.drop(['area_per_inhbt', 'perc_green_area'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5cde19",
   "metadata": {},
   "source": [
    "#### Classification of green area statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29300679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply \"percentile_5\" function to classify the green_stats data into equal percentiles based on 'area_per_inhbt' column\n",
    "percentile_5(green_stats_zscore, 'z_area_per_inhbt',5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply \"add_status_column\" function using the classified \"_percentile column\"\n",
    "add_status_column(green_stats_zscore, 'z_area_per_inhbt_percentile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577694b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge statistics with a subset of the reprojected admin dataframe to enable ploting\n",
    "admin_subset = admin_pop_reproj[['district', 'geometry']]\n",
    "\n",
    "admin_greenstats = pd.merge(admin_subset, green_stats_zscore, left_index=True, right_index=True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa63ca2",
   "metadata": {},
   "source": [
    "## b) Noise Pollution \n",
    "For the noise indicator the assessment aims to identify the area of houses affected by noise and noiseclass per district  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9ccc51",
   "metadata": {},
   "source": [
    "Analysis, filter and cleaning of the housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c41b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop uninmportant columns in the dataset\n",
    "housing_reproj.drop(columns=['anzahlDerU', 'lageZurErd', 'dachart', 'SHAPE_Leng'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2fd44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use geopandas overlay method and interesect operation to determine where the noise layer intersects with the house layer \n",
    "houses_noise = gpd.overlay(housing_reproj, noise_reproj, how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3908255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#translate column names to English\n",
    "houses_noise = houses_noise.rename(columns={'name': 'noiseclass', 'anzahlDerO': 'floors', 'grundflaec':'house_area'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba55e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the dataframe to the admin dataset to enable map creation \n",
    "admin_noisestats = gpd.sjoin(admin_pop_reproj, houses_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a90922",
   "metadata": {},
   "source": [
    "#### Calculation of statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d143ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group the dataset to get the number of houses per noiseclass and district\n",
    "houses_noiseclass = admin_noisestats.groupby(['district', 'noiseclass'])['OBJECTID'].count().reset_index()\n",
    "houses_noiseclass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa93591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mulitply the number of houses with the house area \n",
    "admin_noisestats['total_area'] = admin_noisestats['OBJECTID'] * admin_noisestats['house_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41366ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply the house area with the number of floors to get the total affected residential housing area by noiseclass\n",
    "#convert it to sqkm\n",
    "admin_noisestats['area_floors']=admin_noisestats['total_area']*admin_noisestats['floors'].astype(int)/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783caae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the noiseclass to an integer\n",
    "admin_noisestats['noiseclass'] = admin_noisestats['noiseclass'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98cf8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight the area by noiseclass in view of severity from low to high (increase by 0.5)\n",
    "weights = {0: 0.5, 1: 1, 2: 1.5, 3: 2, 4: 2.5} # dictionary to define the weights\n",
    "#use the pandas.map function to assign the weights and saves results in new column\n",
    "admin_noisestats['weighted_area'] = admin_noisestats['area_floors'] * admin_noisestats['noiseclass'].map(weights) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242e83e9",
   "metadata": {},
   "source": [
    "#### Classification of noise statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c7878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group data by district and weighted area\n",
    "noisestats_weighted = admin_noisestats.groupby('district')['weighted_area'].sum().reset_index()\n",
    "#admin_noisestats.head() # recommended to not display the output due to its size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ef106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the \"percentile_5\" function to classify the weigthed area column in percentiles\n",
    "percentile_5(noisestats_weighted, 'weighted_area',5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the \"add_status_column\" function\n",
    "add_status_column(noisestats_weighted, 'weighted_area_percentile')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b5fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the noise statistics  with a subset of the reprojected admin data to plot later\n",
    "noisestats_merged = pd.merge(admin_subset, noisestats_weighted, left_index=True, right_index=True)\n",
    "noisestats_merged.rename(columns={'district_x': 'district'}, inplace=True)\n",
    "noisestats_merged.drop('district_y', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db2b5c7",
   "metadata": {},
   "source": [
    "## C) Brigthness Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea34fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join the statistics with the shapefile of administrative boundaries \n",
    "temp_bounds = pd.merge(boundaries_reproj,brightnesstemp, on=\"stadtteil_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46db2ce6",
   "metadata": {},
   "source": [
    "#### Classification of temperature brightness data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65faa4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply \"percentile_5\" function to classify MEDIAN column into percentiles\n",
    "percentile_5(temp_bounds, 'MEDIAN',5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ba59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the \"add_status_column\" function on the output of percentile_5 function to add text description\n",
    "add_status_column(temp_bounds, 'MEDIAN_percentile');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a379714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename district column for use in the plotting function \n",
    "temp_bounds=temp_bounds.rename(columns={\"stadtteil_\":\"district\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5db9673",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_bounds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f896b091",
   "metadata": {},
   "source": [
    "# 3) Combined Analysis of Individual Indicators\n",
    "This section combines the indicators to assess the spatial relation between the individual indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dddc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare for merge: subset the social stats dataset to keep only relevant columns for merge\n",
    "soc_subset = admin_socstats[[\"bezirk_nam\",\"district\",\"geometry\", \"status\",\"qt_soc_stats\", \"%unemployed\",\"%social_benefits\",\"%social_housing\"]]\n",
    "#rename status columns in all dataframes to avoid duplications \n",
    "soc_subset=soc_subset.rename(columns={\"status\":\"status_soc\"})\n",
    "green_subset=green_stats_zscore.rename(columns={\"status\":\"status_greens\"})\n",
    "noisestats_subset=noisestats_merged.rename(columns={\"status\":\"status_noise\"})\n",
    "noisestats_subset.drop(columns=['geometry']);\n",
    "tempstats_subset=temp_bounds.rename(columns={\"status\":\"status_temp_b\"})\n",
    "tempstats_subset.drop(columns=['PCT90','RANGE']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4401ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the statistics data set to have one single dataframe for relevant statistics as output\n",
    "stats_merged = green_subset.merge(soc_subset, left_on='stadtteil', right_on='district', how='inner')\n",
    "stats_merged = stats_merged.merge(noisestats_subset, left_on='district', right_on='district', how='right');\n",
    "stats_merged = stats_merged.merge(tempstats_subset, left_on='district', right_on='district', how='right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129e6c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset dataframe to keep only the ouput of the classification\n",
    "stat_indicators=stats_merged[['district','weighted_area_percentile','z_area_per_inhbt_percentile','qt_soc_stats','status_greens','status_noise','MEDIAN_percentile','status_temp_b']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b71c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check data type of columns\n",
    "print(stat_indicators[['district','weighted_area_percentile', 'z_area_per_inhbt_percentile', 'qt_soc_stats','MEDIAN_percentile']].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fe69be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create copy of data \n",
    "stat_indicators_copy = stat_indicators.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a41dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the categorial variables back to integer to be able to perform sum calculations\n",
    "cat_to_int = ['weighted_area_percentile', 'z_area_per_inhbt_percentile', 'qt_soc_stats', 'MEDIAN_percentile']\n",
    "for col in cat_to_int:\n",
    "    stat_indicators_copy[col] = pd.to_numeric(stat_indicators_copy[col], errors='coerce').fillna(0).astype(int) \n",
    "    #converts the type and fills the Null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304c62d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the sum of the environmental indicators per district\n",
    "environmental_burden= stat_indicators_copy.groupby('district')[['weighted_area_percentile', 'z_area_per_inhbt_percentile','MEDIAN_percentile']].sum()\n",
    "environmental_burden['env_multiple_burden'] = environmental_burden.sum(axis=1)\n",
    "environmental_burden = environmental_burden.reset_index()\n",
    "#add the social status indicatur\n",
    "environmental_burden['social_status'] = stat_indicators_copy['qt_soc_stats']\n",
    "#calculate the sum of the combined environmentalindicator and social status indicator\n",
    "environmental_burden['combined_indicators'] = environmental_burden['env_multiple_burden'] + stat_indicators_copy['qt_soc_stats']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dcb471",
   "metadata": {},
   "source": [
    "#### Classification of combined statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41daed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify both new columns in 5 percentiles \n",
    "environmental_burden['env_multiple_burden_percentile'] = pd.qcut(environmental_burden['env_multiple_burden'], q=5, labels=False)\n",
    "environmental_burden['combined_indicators_percentile'] = pd.qcut(environmental_burden['combined_indicators'], q=5, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc48ba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the \"add_status_column function\" to the classified column of the combined_indicators\n",
    "add_status_column(environmental_burden,'combined_indicators_percentile',)\n",
    "environmental_burden.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a1553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the combined statistics with admin data containing the social indicator and geometry column\n",
    "admin_env_soc = environmental_burden.merge(admin_socstats[['district', 'qt_soc_stats', 'geometry']], on='district', suffixes=('_env', '_soc'))\n",
    "#transform the data back to geodataframe\n",
    "combined_indicators = gpd.GeoDataFrame(admin_env_soc, geometry='geometry')\n",
    "combined_indicators.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83b2644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the columns of the combined indicators to the stats_merged dataframe drop NaN values\n",
    "combined_indicators_subset = combined_indicators[['env_multiple_burden','combined_indicators', 'env_multiple_burden_percentile','combined_indicators_percentile']]\n",
    "stats_merged = pd.concat([stats_merged, combined_indicators_subset], axis=1)\n",
    "stats_merged.dropna(axis=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e1a450",
   "metadata": {},
   "source": [
    "# 4)  Visualizations of Indicators\n",
    "Create maps and plots for the different indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3885ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply the \"plot_stats\" function to plot the social status indicator \n",
    "plot_stats(admin_socstats,\"Hamburg Environmental Justice Map - Indicator: Social Status\", \"Oranges\", \"./output/map_social_status.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0cbaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the \"plot_stats\" function to plot the green supply indicator \n",
    "plot_stats(admin_greenstats, \"Hamburg Environmental Justice Map - Indicator: Green Area Supply\", \"YlGn\", \"./output/map_green_supply.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d715e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the \"plot_stats\" function to plot the noise pollution indicator \n",
    "plot_stats(noisestats_merged, \"Hamburg Environmental Justice Map - Indicator: Noise Pollution\", \"Blues\",\"./output/map_noise_pollution.png\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a0bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the \"plot_stats\" function to plot the thermal burden indicator \n",
    "plot_stats(temp_bounds, \"Hamburg Environmental Justice Map - Indicator: Thermal Burden\", \"YlOrRd\", \"./output/map_thermal_burden.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43943b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the \"plot_stats\" function to plot the combined indicator (total of combined indicators)\n",
    "plot_stats(combined_indicators, \"Hamburg - Integrated Environmental Burden & Social Status Index\", \"RdPu\",\"./output/map_integrated_indicator.png\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2365bc5",
   "metadata": {},
   "source": [
    "## a) Plots \n",
    "Create plots to visualize distribution of cateogrial variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975439f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts the number of occurances of each individual indicator per percentile ranking\n",
    "counts_occurrence = pd.DataFrame({\n",
    "    'qt_soc_stats': stats_merged['qt_soc_stats'].value_counts(),\n",
    "    'weighted_area_percentile': stats_merged['weighted_area_percentile'].value_counts(),\n",
    "    'z_area_per_inhbt_percentile': stats_merged['z_area_per_inhbt_percentile'].value_counts(),\n",
    "    'MEDIAN_percentile': stats_merged['MEDIAN_percentile'].value_counts(),\n",
    "\n",
    "})\n",
    "counts_occurrence\n",
    "\n",
    "#rename column names to make it nicer for plotting\n",
    "counts_occurrence=counts_occurrence.rename(columns={\"qt_soc_stats\":\"Social_status\",\"weighted_area_percentile\":\"Noise Pollution\",\"z_area_per_inhbt_percentile\":\"Green Area Supply \",\"MEDIAN_percentile\":\"Thermal Burden\" })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c00e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_occurrence.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6727f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create plot with  occurances\n",
    "plt.figure()\n",
    "plt.style.use('bmh')\n",
    "\n",
    "counts_occurrence.plot(kind='bar')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Indicator')\n",
    "plt.title('Occurance of Indicators classified by percentiles', fontsize=12)\n",
    "plt.ylim(0, 40)\n",
    "plt.legend(title='Indicator', fontsize=7 ,ncols=4)\n",
    "plt.text( 2, -5, 'Status class = 0:very low,1:low, 2:medium, 3:high, 4: very high', ha='center', fontsize=6)\n",
    "plt.savefig('./output/occurance_plot.png') #save the plot to the output folder\n",
    "\n",
    "plt.show()   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create correlation matrix of individual indicators \n",
    "stats_merged.dropna()\n",
    "corr=stats_merged[['weighted_area_percentile', 'qt_soc_stats','z_area_per_inhbt', 'MEDIAN_percentile','%unemployed', '%social_benefits']].corr().style.background_gradient(cmap=\"GnBu\")\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be4e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data wit statistics to csv\n",
    "stats_merged.to_csv(\"./output/stats_merged.csv\")\n",
    "noisestats_weighted.to_csv(\"./output/noise_stats.csv\")\n",
    "green_stats_zscore.to_csv(\"./output/green_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b56782",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9f6e02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
